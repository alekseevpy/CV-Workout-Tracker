import streamlit as st
import cv2
import numpy as np
import tempfile
import os
from pathlib import Path

# run with "streamlit run backend/app.py"

st.set_page_config(
    page_title="–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –≤–æ—Ä–∫–∞—É—Ç –∑–æ–Ω–µ",
    page_icon="üí™",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== STYLING ====================
st.markdown("""
    <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: bold;
            color: #1f47e5;
            margin-bottom: 0.5rem;
        }
        .info-box {
            padding: 1.5rem;
            border-radius: 0.5rem;
            border-left: 4px solid #1f47e5;
            margin: 1rem 0;
        }
        .error-box {
            padding: 1rem;
            border-radius: 0.5rem;
            background-color: #f8d7da;
            border-left: 4px solid #dc3545;
        }
    </style>
""", unsafe_allow_html=True)

# ==================== HELPER FUNCTIONS ====================

def save_uploaded_file(uploaded_file):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é"""
    temp_dir = tempfile.gettempdir()
    file_path = os.path.join(temp_dir, uploaded_file.name)
    
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    return file_path


def get_video_properties(video_path):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ –≤–∏–¥–µ–æ"""
    cap = cv2.VideoCapture(video_path)
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = frame_count / fps if fps > 0 else 0
    
    cap.release()
    
    return {
        "fps": fps,
        "frame_count": frame_count,
        "width": width,
        "height": height,
        "duration": duration
    }


def run_detection_on_video(video_path, model=None, progress_bar=None):
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é –Ω–∞ –≤–∏–¥–µ–æ
    
    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
        model: –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ (–µ—Å–ª–∏ None, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ)
        progress_bar: Streamlit progress bar –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    
    Returns:
        –ø—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ
    """
    cap = cv2.VideoCapture(video_path)
    
    # –ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ –≤–∏–¥–µ–æ
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # –°–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
    temp_dir = tempfile.gettempdir()
    # output_path = os.path.join(temp_dir, "processed_video.mp4")
    output_path = os.path.join(temp_dir, "processed_video.webm")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å VideoWriter
    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fourcc = cv2.VideoWriter_fourcc(*'VP80')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_idx = 0
    
    while True:
        ret, frame = cap.read()
        
        if not ret:
            break
        
        if model is not None:
            pass # todo –Ω–∞–¥–æ —Å—é–¥–∞ –ø–æ–¥–≥—Ä—É–∂–∞—Ç—å –Ω–∞—à—É –º–æ–¥–µ–ª—å
            
        
        out.write(frame)
        frame_idx += 1
        
        # –û–±–Ω–æ–≤–∏—Ç—å progress bar
        if progress_bar is not None:
            progress = frame_idx / frame_count
            progress_bar.progress(progress)
    
    cap.release()
    out.release()
    
    return output_path

def run_pose_estimation_on_video(video_path, model=None, progress_bar=None):
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏ / –ø–æ–∑—ã –Ω–∞ –≤–∏–¥–µ–æ.

    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
        model: –º–æ–¥–µ–ª—å –ø–æ–∑–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∏–¥–µ–æ —Å–æ —Å–∫–µ–ª–µ—Ç–æ–º –∏ —Ç–µ–∫—Å—Ç)
        progress_bar: Streamlit progress bar –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

    Returns:
        (–ø—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π)
    """
    cap = cv2.VideoCapture(video_path)

    # –ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ –≤–∏–¥–µ–æ
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # –°–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
    temp_dir = tempfile.gettempdir()
    # output_path = os.path.join(temp_dir, "pose_video.mp4")
    output_path = os.path.join(temp_dir, "pose_video.webm")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å VideoWriter
    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fourcc = cv2.VideoWriter_fourcc(*'VP80')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_idx = 0

    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    recommendations = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if model is not None:
            pass # todo –Ω–∞–¥–æ —Å—é–¥–∞ –ø–æ–¥–≥—Ä—É–∂–∞—Ç—å –Ω–∞—à—É –º–æ–¥–µ–ª—å

        out.write(frame)
        frame_idx += 1

        # –û–±–Ω–æ–≤–∏—Ç—å progress bar
        if progress_bar is not None and frame_count > 0:
            progress = frame_idx / frame_count
            progress_bar.progress(progress)

    cap.release()
    out.release()

    # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç
    if not recommendations:
        recommendations_text = (
            "–ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞."
        )
    else:
        # –£–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ —Å–∫–ª–µ–∏–≤–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        recommendations = list(dict.fromkeys(recommendations))
        recommendations_text = "\n".join(f"- {r}" for r in recommendations)

    return output_path, recommendations_text


def display_video_preview(video_path, max_frames=5):
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–≤—å—é –≤–∏–¥–µ–æ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ—Ä–µ–π–º–æ–≤)"""
    cap = cv2.VideoCapture(video_path)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    frame_indices = np.linspace(0, frame_count - 1, max_frames, dtype=int)
    
    cols = st.columns(max_frames)
    
    for idx, col in enumerate(cols):
        frame_num = frame_indices[idx]
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        ret, frame = cap.read()
        
        if ret:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            col.image(frame_rgb)
            col.caption(f"Frame {frame_num}")
    
    cap.release()


# ==================== MAIN APP ====================

st.markdown("<h1 class='main-header'>–ü—Ä–æ–µ–∫—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ –≤–æ—Ä–∫–∞—É—Ç –∑–æ–Ω–µ<br/>–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è</h1>", unsafe_allow_html=True)
st.markdown("""
    - **–í–∫–ª–∞–¥–∫–∞ "–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤":** –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ —Å –≤–æ—Ä–∫–∞—É—Ç –ø–ª–æ—â–∞–¥–∫–∏, –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–≤–µ–¥–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é —Ç—Ä–µ–Ω–∞–∂–µ—Ä–æ–≤ –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π. –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ —Å bounding boxes –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.
    - **–í–∫–ª–∞–¥–∫–∞ "–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏":** –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è, –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–≤–µ–¥–µ—Ç –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π (pose estimation + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏)
""")

st.markdown("<div class='info-box'>–í–∏–¥–µ–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP4, MOV –∏–ª–∏ AVI</div>", unsafe_allow_html=True)

tab1, tab2 = st.tabs(["–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤", "–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏"])

# ==================== TAB 1: DETECTION ====================
with tab1:
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ")
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª",
            type=["mp4", "mov", "avi"],
            help="–°—Ç–∞—Ç–∏—á–Ω–æ–µ –≤–∏–¥–µ–æ —Å –≤–æ—Ä–∫–∞—É—Ç –ø–ª–æ—â–∞–¥–∫–∏"
        )

    with col2:
        st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–¥–µ–æ")
        video_info_placeholder = st.empty()

    if uploaded_file is not None:
        st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        video_path = save_uploaded_file(uploaded_file)
        
        # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
        video_props = get_video_properties(video_path)
        
        with video_info_placeholder.container():
            st.markdown(f"""
                - **–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ:** {video_props['width']}x{video_props['height']}
                - **FPS:** {video_props['fps']}
                - **–ö–æ–ª-–≤–æ —Ñ—Ä–µ–π–º–æ–≤:** {video_props['frame_count']}
                - **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {video_props['duration']:.2f} —Å–µ–∫
            """)
        
        st.subheader("–ü—Ä–µ–≤—å—é –≤–∏–¥–µ–æ")
        display_video_preview(video_path, max_frames=5)
        
        st.divider()
        
        process_button = st.button(
            "–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é",
            use_container_width=True,
            key="process_btn"
        )
        
        if "detection_processed_path" not in st.session_state:
            st.session_state.detection_processed_path = None

        if process_button:
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∏–¥–µ–æ..."):
                progress_bar = st.progress(0)
                
                output_video_path = run_detection_on_video(
                    video_path,
                    model=None, # todo –≤—Å—Ç–∞–≤–∏—Ç—å –Ω–∞—à –ø–∞–π–ø–ª–∞–π–Ω
                    progress_bar=progress_bar
                )
                
                progress_bar.empty()
                st.success(f"‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            st.session_state.detection_processed_path = output_video_path

        if st.session_state.detection_processed_path is not None:
            st.subheader("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ")
            with open(st.session_state.detection_processed_path, "rb") as video_file:
                st.video(video_file)
            
            st.divider()
            
            with open(st.session_state.detection_processed_path, "rb") as video_file:
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ",
                    data=video_file.read(),
                    file_name="processed_workout_video.mp4",
                    mime="video/mp4",
                    use_container_width=True
                )

# ==================== TAB 2: POSE ANALYSIS ====================
with tab2:
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è")
        uploaded_pose_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è",
            type=["mp4", "mov", "avi"],
            help="–í–∏–¥–µ–æ –æ–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞, –≤—ã–ø–æ–ª–Ω—è—é—â–µ–≥–æ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ",
            key="pose_video_uploader"
        )

    with col2:
        st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–¥–µ–æ")
        pose_video_info_placeholder = st.empty()

    if uploaded_pose_file is not None:
        st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_pose_file.name}")

        pose_video_path = save_uploaded_file(uploaded_pose_file)
        pose_video_props = get_video_properties(pose_video_path)

        with pose_video_info_placeholder.container():
            st.markdown(f"""
                - **–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ:** {pose_video_props['width']}x{pose_video_props['height']}
                - **FPS:** {pose_video_props['fps']}
                - **–ö–æ–ª-–≤–æ —Ñ—Ä–µ–π–º–æ–≤:** {pose_video_props['frame_count']}
                - **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {pose_video_props['duration']:.2f} —Å–µ–∫
            """)

        st.subheader("–ü—Ä–µ–≤—å—é –≤–∏–¥–µ–æ")
        display_video_preview(pose_video_path, max_frames=5)

        st.divider()

        analyze_button = st.button(
            "–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏",
            use_container_width=True,
            key="analyze_pose_btn"
        )

        if "pose_processed_path" not in st.session_state:
            st.session_state.pose_processed_path = None

        if analyze_button:
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ—Ö–Ω–∏–∫—É..."):
                progress_bar = st.progress(0)
                
                pose_video_out_path, recommendations_text = run_pose_estimation_on_video(
                    pose_video_path,
                    model=None, # todo –Ω–∞—à—É –º–æ–¥–µ–ª—å –≤—Å—Ç–∞–≤–∏—Ç—å
                    progress_bar=progress_bar
                )

                progress_bar.empty()
                st.success(f"‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            st.session_state.pose_processed_path = pose_video_out_path
            st.session_state.pose_recommendations_text = recommendations_text

        if st.session_state.pose_processed_path is not None:                
            col_video, col_text = st.columns([2, 1])

            with col_video:
                st.subheader("–í–∏–¥–µ–æ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ–∑—ã")
                with open(st.session_state.pose_processed_path, "rb") as video_file:
                    st.video(video_file)

            with col_text:
                st.subheader("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é")
                st.text(st.session_state.pose_recommendations_text)

            st.divider()

            with open(st.session_state.pose_processed_path, "rb") as video_file:
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ",
                    data=video_file.read(),
                    file_name="pose_workout_video.mp4",
                    mime="video/mp4",
                    use_container_width=True
                )