{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f233d81",
   "metadata": {},
   "source": [
    "### Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовое обновление инструментов\n",
    "%pip install -U pip setuptools wheel\n",
    "\n",
    "# PyTorch \n",
    "%pip install -U torch torchvision torchaudio\n",
    "\n",
    "# Установщик OpenMMLab\n",
    "%pip install -U openmim\n",
    "\n",
    "# MMEngine и MMCV 2.1.x\n",
    "!mim install \"mmengine>=0.10.0\"\n",
    "!mim install \"mmcv==2.1.0\"\n",
    "\n",
    "# MMDetection для авто-детекции людей 3.2.x\n",
    "!mim install \"mmdet==3.2.0\"\n",
    "\n",
    "# MMPose 1.x\n",
    "!mim install \"mmpose==1.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U gdown imageio-ffmpeg --quiet\n",
    "%pip install -q -U imageio imageio-ffmpeg\n",
    "\n",
    "%pip install -U \"numpy==2.2.6\" cython\n",
    "\n",
    "# снесём и пересоберём оба COCO-пакета\n",
    "%pip uninstall -y xtcocotools pycocotools\n",
    "%pip install --no-binary=xtcocotools,pycocotools --no-cache-dir xtcocotools pycocotools\n",
    "\n",
    "# на всякий случай переустановим mmpose (поверх тех же версий)\n",
    "%pip install -U --no-cache-dir \"mmpose==1.3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d5c041",
   "metadata": {},
   "source": [
    "### Перезапускаем ядро, проверяем версии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf711b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import xtcocotools._mask as _mask\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "\n",
    "def _ver(pkg):\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        return getattr(m, \"__version__\", \"N/A\")\n",
    "    except Exception as e:\n",
    "        return f\"not installed ({e})\"\n",
    "\n",
    "\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"\\ntorch:\", _ver(\"torch\"))\n",
    "print(\"torchvision:\", _ver(\"torchvision\"))\n",
    "print(\"mmengine:\", _ver(\"mmengine\"))\n",
    "print(\"mmcv:\", _ver(\"mmcv\"))\n",
    "print(\"mmdet:\", _ver(\"mmdet\"))\n",
    "print(\"\\nMMPoseInferencer import OK\")\n",
    "print(\"mmpose:\", _ver(\"mmpose\"))\n",
    "print(\"\\nxtcocotools with numpy version:\", _ver(\"numpy\"))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\\nDevice selected:\", \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c3675",
   "metadata": {},
   "source": [
    "### Каталоги проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd43c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "INPUT_DIR = BASE_DIR / \"input\"\n",
    "OUTPUT_DIR = BASE_DIR / \"output\"\n",
    "WEIGHTS_DIR = BASE_DIR / \"weights\"\n",
    "INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"BASE_DIR =\", BASE_DIR)\n",
    "print(\"INPUT_DIR =\", INPUT_DIR)\n",
    "print(\"OUTPUT_DIR =\", OUTPUT_DIR)\n",
    "print(\"WEIGHTS_DIR =\", WEIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38541133",
   "metadata": {},
   "source": [
    "# Попытка на фото"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d5e3f",
   "metadata": {},
   "source": [
    "### 1. Скачиваем изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eed2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "GD_URL = \"https://drive.google.com/file/d/1RenekFPFYrB1UhAHhdZf67LeCUw8WbZh/view?usp=sharing\"\n",
    "img_path = INPUT_DIR / \"cheliki_na_turnike.jpg\"\n",
    "\n",
    "gdown.download(GD_URL, str(img_path), quiet=False, fuzzy=True)\n",
    "assert img_path.exists(), f\"Изображение не скачалось: {img_path}\"\n",
    "\n",
    "print(\"Скачано в:\", img_path)\n",
    "print(\"Размер: {:.2f} МБ\".format(img_path.stat().st_size / (1024**2)))\n",
    "\n",
    "display(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed416c4",
   "metadata": {},
   "source": [
    "### 2. Применяем MMPoseInferencer на скачанном изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    torch.serialization.add_safe_globals(\n",
    "        [\n",
    "            np.core.multiarray._reconstruct,\n",
    "            np.dtype,\n",
    "            np.ufunc,\n",
    "        ]\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Используем изображение:\", img_path)\n",
    "\n",
    "# Инициализируем унифицированный инференсер MMPose\n",
    "# с alias \"human\" (детектор + оценка позы)\n",
    "inferencer = MMPoseInferencer(\"human\", device=device)\n",
    "\n",
    "result_gen = inferencer(\n",
    "    str(img_path),\n",
    "    return_vis=True,  # вернуть массив визуализации в result['visualization']\n",
    "    show=False,  # не открывать отдельное окно\n",
    "    radius=16,\n",
    "    thickness=8,  # сделать точки/скелет чуть заметнее\n",
    "    vis_out_dir=str(\n",
    "        OUTPUT_DIR / \"vis\"\n",
    "    ),  # сюда сохранятся картинки с разметкой\n",
    "    pred_out_dir=str(OUTPUT_DIR / \"pred\"),  # сюда — JSON с ключевыми точками\n",
    ")\n",
    "\n",
    "result = next(result_gen)\n",
    "\n",
    "vis_list = result.get(\"visualization\", [])\n",
    "if not vis_list:\n",
    "    raise RuntimeError(\n",
    "        \"Нет визуализации в результате. Убедитесь, что return_vis=True.\"\n",
    "    )\n",
    "\n",
    "vis_img = vis_list[\n",
    "    0\n",
    "]  # это RGB-изображение с нарисованными ключевыми точками/скелетом\n",
    "\n",
    "# 5) Сохраним и покажем\n",
    "out_file = OUTPUT_DIR / f\"{img_path.stem}_pose_vis.jpg\"\n",
    "# cv2.imwrite ожидает BGR -> конвертируем\n",
    "cv2.imwrite(str(out_file), vis_img[..., ::-1])\n",
    "\n",
    "print(\"Визуализация сохранена в:\", out_file)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(vis_img)  # vis_img уже в RGB\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"MMPose: скелетики на изображении\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858486e",
   "metadata": {},
   "source": [
    "# Попытка на видео"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e933a",
   "metadata": {},
   "source": [
    "### 1. Скачиваем видео и анализируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, gdown\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "GD_URL = \"https://drive.google.com/file/d/1iDHBbYgV_sYRyVUi_BLdqcGogD_CDXmB/view?usp=sharing\"\n",
    "video_pth = INPUT_DIR / \"tiktonik_360p.mp4\"\n",
    "\n",
    "video_pth.unlink(missing_ok=True)\n",
    "gdown.download(GD_URL, str(video_pth), quiet=False, fuzzy=True)\n",
    "assert video_pth.exists(), f\"Видео не скачалось: {video_pth}\"\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_pth))\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Не удалось открыть видео: {video_pth}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)\n",
    "n = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "cap.release()\n",
    "\n",
    "print(f\"Видео: {video_pth}\")\n",
    "print(f\"Размер: {w}x{h}, FPS: {fps:.3f}, кадров: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8de363",
   "metadata": {},
   "source": [
    "### 2. Применяем MMPoseInferencer на скачанном видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3168d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, imageio, numpy as np, torch, os\n",
    "from pathlib import Path\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "# Пути и устройство\n",
    "device = \"cpu\"  # на macOS так избегаем проблемы NMS на MPS\n",
    "out_dir = OUTPUT_DIR / \"tiktonik_pose\"\n",
    "\n",
    "# Инициализируем единый инференсер с alias \"human\"\n",
    "# (под капотом подтянет RTMDet для людей + 2D-позу; умеет видео/изображения;\n",
    "# настраиваемые radius/thickness)\n",
    "inferencer = MMPoseInferencer(\n",
    "    \"human\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Готовим writer с кодеком H.264\n",
    "vis_dir = out_dir / \"visualization\"\n",
    "vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_video = vis_dir / (video_pth.stem + \"_pose.mp4\")\n",
    "\n",
    "writer = imageio.get_writer(\n",
    "    out_video.as_posix(),\n",
    "    fps=fps,\n",
    "    codec=\"libx264\",\n",
    "    format=\"FFMPEG\",\n",
    "    output_params=[\"-pix_fmt\", \"yuv420p\"],\n",
    ")\n",
    "\n",
    "# Запускаем ленивый генератор инференса по видео.\n",
    "# Чтобы получать кадры с отрисовкой в Python, включаем return_vis=True\n",
    "# и задаем толщину/радиус. При желании можно включить/выключить рамки:\n",
    "# draw_bbox=True/False.\n",
    "result_gen = inferencer(\n",
    "    str(video_pth),\n",
    "    show=False,\n",
    "    return_vis=True,\n",
    "    radius=16,\n",
    "    thickness=8,\n",
    "    draw_bbox=False,\n",
    ")\n",
    "\n",
    "# Пробегаем все результаты и пишем в MP4\n",
    "frames_written = 0\n",
    "for res in result_gen:\n",
    "    # 1) Заберём визуализацию (может быть списком или None)\n",
    "    vis = res.get(\"visualization\")\n",
    "    if isinstance(vis, list):\n",
    "        vis = vis[0] if vis else None\n",
    "\n",
    "    # 2) Если отрисовка вернулась путём (бывает), читаем с диска\n",
    "    if vis is None:\n",
    "        vis_path = res.get(\"visualization_path\")\n",
    "        if isinstance(vis_path, list):\n",
    "            vis_path = vis_path[0] if vis_path else None\n",
    "        if vis_path:\n",
    "            vis = imageio.v2.imread(vis_path)  # RGB\n",
    "\n",
    "    if vis is None:\n",
    "        continue  # нечего писать\n",
    "\n",
    "    # 3) Приводим к RGB uint8 HxWx3\n",
    "    frame = np.asarray(vis)\n",
    "    if frame.ndim == 2:  # если ч/б\n",
    "        frame = np.repeat(frame[..., None], 3, axis=2)\n",
    "    elif (\n",
    "        frame.ndim == 3 and frame.shape[2] == 4\n",
    "    ):  # если RGBA — отбрасываем альфу\n",
    "        frame = frame[..., :3]\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = np.clip(frame, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # 4) Подгоним размер под исходное видео (на всякий)\n",
    "    if frame.shape[1] != w or frame.shape[0] != h:\n",
    "        frame = cv2.resize(frame, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # 5) Пишем в MP4 (imageio ожидает RGB)\n",
    "    writer.append_data(frame)\n",
    "    frames_written += 1\n",
    "    if frames_written % 50 == 0:\n",
    "        print(f\"Обработано кадров: {frames_written}\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"Готово! Сохранено кадров: {frames_written}\")\n",
    "print(\"Выходной файл:\", out_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
